#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import glob
import os
import math
import re
import shutil
import subprocess  # nosec
import sys
import tempfile
import time
import traceback
from typing import cast, List, Dict, Any, Tuple, Union, Optional, Callable
import yaml
from skimage.measure import compare_ssim
import numpy as np
import cv2
from scipy.signal import find_peaks


CONVERT = ['gm', 'convert']


def rotate_image(
        image: np.ndarray, angle: float, background: Union[int, Tuple[int, int, int]]
) -> np.ndarray:
    old_width, old_height = image.shape[:2]
    angle_radian = math.radians(angle)
    width = abs(np.sin(angle_radian) * old_height) + abs(np.cos(angle_radian) * old_width)
    height = abs(np.sin(angle_radian) * old_width) + abs(np.cos(angle_radian) * old_height)

    image_center = tuple(np.array(image.shape[1::-1]) / 2)
    rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)
    rot_mat[1, 2] += (width - old_width) / 2
    rot_mat[0, 2] += (height - old_height) / 2
    return cv2.warpAffine(image, rot_mat, (int(round(height)), int(round(width))), borderValue=background)


def crop_image(  # pylint: disable=too-many-arguments
        image: np.ndarray, x: int, y: int, width: int, height: int,
        background: Union[int, Tuple[int, int, int]]
) -> np.ndarray:
    matrice = np.array([
        [1.0, 0.0, -x],
        [0.0, 1.0, -y],
    ])
    return cv2.warpAffine(image, matrice, (int(round(width)), int(round(height))), borderValue=background)


class Context:  # pylint: disable=too-many-instance-attributes
    def __init__(  # pylint: disable=too-many-arguments
            self,
            config: Dict[str, Any],
            step: Dict[str, Any],
            config_file_name: Optional[str] = None,
            root_folder: Optional[str] = None,
            image_name: Optional[str] = None
    ) -> None:
        self.config = config
        self.step = step
        self.config_file_name = config_file_name
        self.root_folder = root_folder
        self.image_name = image_name
        self.image: Optional[np.ndarray] = None
        self.mask: Optional[np.ndarray] = None
        self.mask_ready: Optional[np.ndarray] = None
        self.process_count = self.step.get('process_count', 0)

    def init_mask(self) -> None:
        if self.image is None:
            raise Exception('The image is None')
        if self.mask is None:
            raise Exception('The mask is None')
        self.mask_ready = cv2.resize(
            cv2.cvtColor(self.mask, cv2.COLOR_BGR2GRAY),
            (self.image.shape[1], self.image.shape[0]),
        )

    def get_process_count(self) -> int:
        try:
            return self.process_count
        finally:
            self.process_count += 1

    def get_masked(self) -> np.ndarray:
        if self.image is None:
            raise Exception('The image is None')
        if self.mask_ready is None:
            return self.image

        image = self.image.copy()
        image[self.mask_ready == 0] = (255, 255, 255)
        return image

    def crop(self, x: int, y: int, width: int, height: int) -> None:
        if self.image is None:
            raise Exception('The image is None')
        self.image = crop_image(self.image, x, y, width, height, (255, 255, 255))
        if self.mask_ready is not None:
            self.mask_ready = crop_image(self.mask_ready, x, y, width, height, 0)

    def rotate(self, angle: float) -> None:
        if self.image is None:
            raise Exception('The image is None')
        self.image = rotate_image(self.image, angle, (255, 255, 255))
        if self.mask_ready is not None:
            self.mask_ready = rotate_image(self.mask_ready, angle, 0)


def add_intermediate_error(
        config: Dict[str, Any],
        config_file_name: Optional[str],
        error: Exception,
        traceback_: List[str]
) -> None:
    if config_file_name is None:
        raise Exception('The config file name is required')
    if 'intermediate_error' not in config:
        config['intermediate_error'] = []

    old_intermediate_error: List[Dict[str, Any]] = []
    old_intermediate_error.extend(config['intermediate_error'])
    try:
        config['intermediate_error'].append({
            'error': error,
            'traceback': traceback_,
        })
        with open(config_file_name + '_', 'w') as config_file:
            config_file.write(yaml.safe_dump(config, default_flow_style=False))
    except Exception as exception:
        print(exception)
        config['intermediate_error'] = old_intermediate_error
        config['intermediate_error'].append({
            'error': str(error),
            'traceback': traceback_,
        })
        with open(config_file_name + '_', 'w') as config_file:
            config_file.write(yaml.safe_dump(config, default_flow_style=False))
    os.rename(config_file_name + '_', config_file_name)


def call(cmd: Union[str, List[str]], **kwargs: Any) -> None:
    if isinstance(cmd, list):
        cmd = [str(element) for element in cmd]
    print(' '.join(cmd) if isinstance(cmd, list) else cmd)
    sys.stdout.flush()
    subprocess.check_output(cmd, stderr=subprocess.PIPE, **kwargs)  # nosec


def output(cmd: Union[str, List[str]], **kwargs: Any) -> str:
    if isinstance(cmd, list):
        cmd = [str(element) for element in cmd]
    print(' '.join(cmd) if isinstance(cmd, list) else cmd)
    sys.stdout.flush()
    return cast(bytes, subprocess.check_output(cmd, stderr=subprocess.PIPE, **kwargs)).decode()  # nosec


def image_diff(image1: np.ndarray, image2: np.ndarray) -> Tuple[float, np.ndarray]:
    width = max(image1.shape[1], image2.shape[1])
    height = max(image1.shape[0], image2.shape[0])
    image1 = cv2.resize(image1, (width, height))
    image2 = cv2.resize(image2, (width, height))
    score, diff = compare_ssim(
        cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY),
        cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY),
        full=True
    )
    diff = (255 - diff * 255).astype("uint8")
    return score, diff


class Process:  # pylint: disable=too-few-public-methods
    def __init__(self, name: str, experimental: bool = False, ignore_error: bool = False) -> None:
        self.experimental = experimental
        self.name = name
        self.ignore_error = ignore_error

    def __call__(self, func: Callable) -> Callable:
        def wrapper(context: Context, *args: Any, **kwargs: Any) -> None:
            if context.image is None:
                raise Exception('The image is required')
            if context.root_folder is None:
                raise Exception('The root folder is required')
            if context.image_name is None:
                raise Exception('The image name is required')
            if self.experimental and os.environ.get("EXPERIMENTAL", "FALSE") != "TRUE":
                return
            old_image = context.image.copy() if self.experimental else None
            start_time = time.perf_counter()
            if self.experimental and os.environ.get('TEST_EXPERIMENTAL', 'FALSE') == 'FALSE' \
                    or self.ignore_error:
                try:
                    new_image = func(context, *args, **kwargs)
                    if new_image is not None and self.ignore_error:
                        context.image = new_image
                except Exception as exception:
                    print(exception)
                    add_intermediate_error(
                        context.config, context.config_file_name,
                        exception, traceback.format_exc().split('\n')
                    )
            else:
                new_image = func(context, *args, **kwargs)
                if new_image is not None:
                    context.image = new_image
            elapsed_time = time.perf_counter() - start_time
            if os.environ.get("TIME", "FALSE") == "TRUE":
                print('Elapsed time in {}: {}s.'.format(self.name, int(round(elapsed_time))))
            if self.experimental and context.image is not None:
                score, diff = image_diff(old_image, context.image)
                if diff is not None and score < 1.0:
                    dest_folder = os.path.join(context.root_folder, self.name)
                    if not os.path.exists(dest_folder):
                        os.makedirs(dest_folder)
                    dest_image = os.path.join(dest_folder, context.image_name)
                    cv2.imwrite(dest_image, diff)

            name = self.name if self.experimental else '{}-{}'.format(context.get_process_count(), self.name)
            if self.experimental or os.environ.get("PROGRESS", "FALSE") == "TRUE":
                dest_folder = os.path.join(context.root_folder, name)
                if not os.path.exists(dest_folder):
                    os.makedirs(dest_folder)
                dest_image = os.path.join(dest_folder, context.image_name)
                cv2.imwrite(dest_image, context.image)
                dest_image = os.path.join(dest_folder, 'mask-' + context.image_name)
                cv2.imwrite(dest_image, context.mask_ready)
                dest_image = os.path.join(dest_folder, 'masked-' + context.image_name)
                cv2.imwrite(dest_image, context.get_masked())

        return wrapper


def external(func: Callable) -> Callable:
    def wrapper(context: Context, *args: Any, **kwargs: Any) -> Optional[np.ndarray]:
        source = tempfile.NamedTemporaryFile(suffix='.png')
        cv2.imwrite(source.name, context.image)
        destination = tempfile.NamedTemporaryFile(suffix='.png')
        func(source.name, destination.name, *args, **kwargs)
        return cv2.imread(destination.name)
    return wrapper


def get_contour_to_crop(
        contours: List[Tuple[int, int, int, int]], margin_horizontal: int = 0, margin_vertical: int = 0
) -> Tuple[int, int, int, int]:
    content = [
        contours[0][0],
        contours[0][1],
        contours[0][0] + contours[0][2],
        contours[0][1] + contours[0][3]
    ]
    for contour in contours:
        content[0] = min(content[0], contour[0])
        content[1] = min(content[1], contour[1])
        content[2] = max(content[2], contour[0] + contour[2])
        content[3] = max(content[3], contour[1] + contour[3])

    return (
        content[0] - margin_horizontal,
        content[1] - margin_vertical,
        content[2] - content[0] + 2 * margin_horizontal,
        content[3] - content[1] + 2 * margin_vertical,
    )


def crop(context: Context, margin_horizontal: int = 25, margin_vertical: int = 25) -> None:
    """
    Margin in px
    """
    contours = find_contours(context.get_masked())
    if contours:
        x, y, width, height = get_contour_to_crop(contours, margin_horizontal, margin_vertical)
        context.crop(x, y, width, height)


@Process('force-cleanup')
@external
def force_cleanup(source: str, destination: str, config: Dict[str, Any]) -> None:
    if config['args']['level']:
        call(CONVERT + ['-level', '15%,1,85%', source, destination])
        # Test
        # cv.Threshold(image, image, 15*2.55, 255, cv.THRESH_TOZERO);
        # cv.Threshold(image, image, 85*2.55, 255, cv.THRESH_TRUNC);
        # OR probably better
        # equ = cv.equalizeHist(img)
        # res = np.hstack((img,equ))


@Process('deskew-column-stack', True)
def deskew_column_stack(context: Context) -> None:
    image = context.get_masked()
    contours = find_contours(image, 200)
    if contours:
        x, y, width, height = get_contour_to_crop(contours)
        image = crop_image(image, x, y, width, height, (255, 255, 255))

    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    gray = cv2.bitwise_not(gray)
    thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]

    coords = np.column_stack(np.where(thresh > 0))
    angle = cv2.minAreaRect(coords)[-1]

    if angle < -45:
        angle = -(90 + angle)
    else:
        angle = -angle

    return rotate_image(context.image, angle, (255, 255, 255))
    # context.rotate(angle)


@Process('deskew-hough-lines', True)
def deskew_hough_lines(context: Context) -> None:
    image = context.get_masked()
    contours = find_contours(image, 200)
    if contours:
        x, y, width, height = get_contour_to_crop(contours)
        image = crop_image(image, x, y, width, height, (255, 255, 255))

    # Invert the colors of our image
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    image = cv2.bitwise_not(gray)
    width, height = image.shape

    # Hough transform
    edges = cv2.Canny(image, 150, 200, 3, 5)
    lines = cv2.HoughLinesP(edges, 1, np.pi / 180, 100, minLineLength=width / 2.0, maxLineGap=20)
    lines = lines.reshape(lines.shape[0], 4)

    # Calculate the angle between each line and the horizontal line
    angle = 0.0
    for x1, y1, x2, y2 in lines:
        if x1 != x2:
            angle += np.arctan2(y2 - y1, x2 - x1)
    angle /= lines.size
    angle = angle * 180.0 / np.pi

    print(angle)
    return rotate_image(context.image, angle, (255, 255, 255))
    # context.rotate(angle)


@Process('deskew-ext')
def deskew_ext(context: Context) -> None:
    image = context.get_masked()
    contours = find_contours(image, 200)
    if contours:
        x, y, width, height = get_contour_to_crop(contours)
        image = crop_image(image, x, y, width, height, (255, 255, 255))
    source = tempfile.NamedTemporaryFile(suffix='.png')
    cv2.imwrite(source.name, image)
    out = output(['/opt/Deskew/Bin/deskew', source.name]).split('\n')
    text = 'Skew angle found [deg]: '
    out = [e for e in out if e.startswith(text)]
    angle = float(out[0][len(text):])
    context.rotate(angle)


@Process('docrop')
def docrop(context: Context) -> None:
    # Margin in mm
    marging_horizontal = 9
    maring_vertical = 6
    crop(
        context,
        int(round(marging_horizontal / 10 / 2.51 * 300)),
        int(round(maring_vertical / 10 / 2.51 * 300))
    )


@Process('sharpen')
@external
def sharpen(source: str, destination: str) -> None:
    call(CONVERT + ['-sharpen', '0x2', source, destination])
    # cv::GaussianBlur(frame, image, cv::Size(0, 0), 3);
    # cv::addWeighted(frame, 1.5, image, -0.5, 0, image);


@Process('dither', True)
@external
def dither(source: str, destination: str) -> None:
    call(CONVERT + ['+dither', source, destination])


@Process('autorotate', False, True)
def autorotate(context: Context) -> None:
    source = tempfile.NamedTemporaryFile(suffix='.png')
    cv2.imwrite(source.name, context.get_masked())
    orientation_lst = output([
        'tesseract', source.name, '-', '--psm', '0', '-l', 'osd'
    ]).splitlines()
    orientation_lst = [
        e for e in orientation_lst if 'Orientation in degrees' in e
    ]
    context.rotate(int(orientation_lst[0].split()[3]))


def draw_line(  # pylint: disable=too-many-arguments
        image: np.ndarray,
        vertical: bool,
        position: int,
        value: int,
        name: str,
        type_: str
) -> Dict[str, Any]:
    img_len = image.shape[0 if vertical else 1]
    color = (255, 0, 0) if vertical else (0, 255, 0)
    if vertical:
        cv2.rectangle(
            image, (int(position) - 1, img_len), (int(position) + 0, img_len - value), color, -1
        )
        cv2.putText(
            image, name, (int(position), img_len - value), cv2.FONT_HERSHEY_SIMPLEX, 2.0, color, 4
        )
    else:
        cv2.rectangle(
            image, (0, int(position) - 1), (value, int(position) + 0), color, -1
        )
        cv2.putText(
            image, name, (value, int(position)), cv2.FONT_HERSHEY_SIMPLEX, 2.0, color, 4
        )
    return {
        'name': name,
        'type': type_,
        'value': int(position),
        'vertical': vertical,
        'margin': 0,
    }


def find_lines(image: np.ndarray, vertical: bool) -> Tuple[np.ndarray, Dict[str, np.ndarray]]:
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    edges = cv2.Canny(gray, 50, 150, apertureSize=3)
    lines = cv2.HoughLinesP(
        image=edges, rho=0.02, theta=np.pi / 500, threshold=10, lines=np.array([]), minLineLength=100,
        maxLineGap=100
    )

    values = np.zeros(image.shape[1 if vertical else 0])
    for index in range(lines.shape[0]):
        line = lines[index][0]
        if line[0 if vertical else 1] == line[2 if vertical else 3]:
            values[line[0 if vertical else 1]] += \
                line[1 if vertical else 0] - line[3 if vertical else 2]
    correlated_values = np.correlate(values, [
        .2, .6, 1, .6, .2
    ])
    dist = 1.0
    peaks, properties = find_peaks(correlated_values, height=dist * 10, distance=dist)
    while len(peaks) > 5:
        dist *= 1.3
        peaks, properties = find_peaks(correlated_values, height=dist * 10, distance=dist)
    peaks += 2

    return peaks, properties


def zero_ranges(values: np.ndarray) -> np.ndarray:
    # Create an array that is 1 where a is 0, and pad each end with an extra 0.
    iszero = np.concatenate(([0], np.equal(values, 0).view(np.int8), [0]))
    absdiff = np.abs(np.diff(iszero))
    # Runs start and end where absdiff is 1.
    ranges = np.where(absdiff == 1)[0].reshape(-1, 2)
    return ranges


def find_limit_contour(image: np.ndarray, vertical: bool) -> List[int]:
    contours = find_contours(image)
    image_size = image.shape[1 if vertical else 0]

    values = np.zeros(image_size)
    for x, _, width, height in contours:
        for value in range(x, min(x + width, image_size)):
            values[value] += height

    ranges = zero_ranges(values)

    result: List[int] = []
    for ranges_ in ranges:
        if ranges_[0] != 0 and ranges_[1] != image_size:
            result.append(int(round(sum(ranges_) / 2)))

    return result


def fill_limits(image: np.ndarray, vertical: bool) -> List[Dict[str, Any]]:
    peaks, properties = find_lines(image, vertical)
    contours = find_limit_contour(image, vertical)
    third_image_size = int(image.shape[0 if vertical else 1] / 3)
    limits: List[Dict[str, Any]] = []
    prefix = 'V' if vertical else 'H'
    for index, peak in enumerate(peaks):
        value = int(round(properties['peak_heights'][index] / 3))
        limits.append(draw_line(
            image, vertical, peak, value, '{}L{}'.format(prefix, index), 'line detection'
        ))
    for index, contour in enumerate(contours):
        limits.append(draw_line(
            image, vertical, contour, third_image_size, '{}C{}'.format(prefix, index), 'contour detection'
        ))
    if not limits:
        half_image_size = image.shape[1 if vertical else 0] / 2
        limits.append(draw_line(
            image, vertical, half_image_size, third_image_size, '{}C'.format(prefix), 'image center'
        ))

    return limits


def find_contours(image: np.ndarray, min_size: int = 32) -> List[Tuple[int, int, int, int]]:
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

    # Clean the image using otsu method with the inversed binarized image
    thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 17, 25)

    # Assign a rectangle kernel size
    kernel = np.ones((5, 5), 'uint8')
    par_img = cv2.dilate(thresh, kernel, iterations=5)

    contours, _ = cv2.findContours(par_img.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    result = []

    for cnt in contours:
        x, y, width, height = cv2.boundingRect(cnt)
        if width > min_size and height > min_size:
            result.append((x + 8, y + 8, width - 16, height - 16))

    return result


@Process('scantailor', True)
@external
def scantailor(source: str, destination: str) -> None:
    call([
        'scantailor-cli', '--dpi=300', '--content-detection=normal',
        '--output-dpi=300', '--color-mode=color_grayscale',
        source, os.path.dirname(destination)
    ])


@Process('scantailor-1200', True)
@external
def scantailor_1200(source: str, destination: str) -> None:
    call([
        'scantailor-cli', '--dpi=300', '--content-detection=normal',
        '--output-dpi=300', '--color-mode=color_grayscale',
        source, os.path.dirname(destination)
    ])


@Process('scantailor-advanced', True)
@external
def scantailor_advanced(source: str, destination: str) -> None:
    call([
        'scantailor-advanced-cli', '--dpi=300', '--content-detection=normal',
        '--output-dpi=300', '--color-mode=color_grayscale',
        source, os.path.dirname(destination)
    ])


@Process('scantailor-advanced-1200', True)
@external
def scantailor_advanced_1200(source: str, destination: str) -> None:
    call([
        'scantailor-advanced-cli', '--dpi=300', '--content-detection=normal',
        '--output-dpi=300', '--color-mode=color_grayscale',
        source, os.path.dirname(destination)
    ])


@Process('scantailor-universal', True)
@external
def scantailor_universal(source: str, destination: str) -> None:
    call([
        'scantailor-universal-cli', '--dpi=300', '--content-detection=normal',
        '--output-dpi=300', '--color-mode=color_grayscale',
        source, os.path.dirname(destination)
    ])


@Process('scantailor-universal-1200', True)
@external
def scantailor_universal_1200(source: str, destination: str) -> None:
    call([
        'scantailor-universal-cli', '--dpi=300', '--content-detection=normal',
        '--output-dpi=300', '--color-mode=color_grayscale',
        source, os.path.dirname(destination)
    ])


@Process('tesseract', True)
@external
def tesseract(source: str, destination: str) -> None:
    call('tesseract -l fra+eng {} stdout pdf > {}'.format(source, destination), shell=True)  # nosec


def transform(
        config: Dict[str, Any],
        step: Dict[str, Any],
        config_file_name: str,
        root_folder: str,
) -> Dict[str, Any]:
    if 'intermediate_error' in config:
        del config['intermediate_error']

    images = []
    process_count = 0

    if config['args']['assisted_split']:
        config['assisted_split'] = []

    for index, img in enumerate(step['sources']):
        context = Context(config, step, config_file_name, root_folder, os.path.basename(img))
        if context.image_name is None:
            raise Exception("Image name is required")
        context.image = cv2.imread(os.path.join(root_folder, img))
        mask_file = os.path.join(os.path.dirname(root_folder), 'mask.png')
        if os.path.exists(mask_file):
            context.mask = cv2.imread(mask_file)
            context.init_mask()
        force_cleanup(context, config)
        deskew_column_stack(context)
        deskew_hough_lines(context)
        deskew_ext(context)
        docrop(context)
        sharpen(context)
        dither(context)
        autorotate(context)

        # Is empty ?
        contours = find_contours(context.get_masked())
        if not contours:
            print("Ignore image with no content: {}".format(img))
            continue

        tesseract(context)
        scantailor(context)
        scantailor_1200(context)
        scantailor_advanced(context)
        scantailor_advanced_1200(context)
        scantailor_universal(context)
        scantailor_universal_1200(context)

        if config['args']['assisted_split']:
            assisted_split: Dict[str, Any] = {}
            name = os.path.join(root_folder, context.image_name)
            assisted_split['source'] = save_image(
                context.image, root_folder,
                '{}-assisted-split'.format(context.get_process_count()), context.image_name, True
            )

            config['assisted_split'].append(assisted_split)
            destinations = [len(step['sources']) * 2 - index, index + 1]
            if index % 2 == 1:
                destinations.reverse()
            assisted_split['destinations'] = destinations

            limits = []
            limits.extend(fill_limits(context.image, True))
            limits.extend(fill_limits(context.image, False))
            assisted_split['limits'] = limits

            cv2.imwrite(name, context.image)
            assisted_split['image'] = context.image_name
            images.append(name)
        else:
            img2 = os.path.join(root_folder, context.image_name)
            cv2.imwrite(img2, context.image)
            images.append(img2)
        process_count = context.process_count

    return {
        'sources': images,
        'name': 'split' if config['args']['assisted_split'] else 'finalise',
        'process_count': process_count,
    }


def save(root_folder: str, img: str, folder: str, force: bool = False) -> str:
    if force or os.environ.get("PROGRESS") == "TRUE":
        dest_folder = os.path.join(root_folder, folder)
        if not os.path.exists(dest_folder):
            os.makedirs(dest_folder)
        dest_file = os.path.join(dest_folder, os.path.basename(img))
        shutil.copyfile(img, dest_file)
        return dest_file
    return img


def save_image(
        image: np.ndarray,
        root_folder: str,
        folder: str,
        name: str,
        force: bool = False
) -> Optional[str]:
    if force or os.environ.get("PROGRESS") == "TRUE":
        dest_folder = os.path.join(root_folder, folder)
        if not os.path.exists(dest_folder):
            os.makedirs(dest_folder)
        dest_file = os.path.join(dest_folder, name)
        cv2.imwrite(dest_file, image)
        return dest_file
    return None


def split(config: Dict[str, Any], step: Dict[str, Any], root_folder: str) -> Dict[str, Any]:
    process_count = 0
    for assisted_split in config['assisted_split']:
        if assisted_split['limits']:
            if len(assisted_split['limits']) != len(assisted_split['destinations']) - 1:
                raise Exception("Wrong number of limits ({}) or destinations ({}) for img '{}'".format(
                    len(assisted_split['limits']),
                    len(assisted_split['destinations']),
                    assisted_split['source'],
                ))
            vertical: bool = assisted_split['limits'][0]['vertical']
            for limit in assisted_split['limits']:
                if limit['vertical'] != vertical:
                    raise Exception("Mix of limit type for img '{}'".format(assisted_split['source']))

    for assisted_split in config['assisted_split']:
        image_path = os.path.join(root_folder, assisted_split['image'])
        if os.path.exists(image_path):
            os.unlink(image_path)

    append: Dict[Union[str, int], List[Dict[str, Any]]] = {}
    transformed_images = []
    for assisted_split in config['assisted_split']:
        context = Context(config, step)
        img = assisted_split['source']
        width, height = [int(e) for e in output(CONVERT + [
            img, '-format', '%w %h', 'info:-'
        ]).strip().split(' ')]
        vertical = assisted_split['limits'][0]['vertical']
        last_pos = 0
        for number, destination in enumerate(assisted_split['destinations']):
            if number < len(assisted_split['limits']):
                limit = assisted_split['limits'][number]
                value = limit['value']
                margin = limit['margin']
            else:
                value = width if vertical else height
                margin = 0
            if destination == '-':
                last_pos = value + margin
            else:
                if number < len(assisted_split['limits']):
                    limit = assisted_split['limits'][number]
                    value = limit['value']
                    margin = limit['margin']
                else:
                    value = width if vertical else height
                    margin = 0
                process_file = tempfile.NamedTemporaryFile(suffix='.png')
                img2 = process_file.name
                if vertical:
                    call(CONVERT + [
                        '-crop', '{}x{}+{}+0'.format(value - margin - last_pos, height, last_pos),
                        '+repage', img, img2
                    ])
                else:
                    call(CONVERT + [
                        '-crop', '{}x{}+0+{}'.format(width, value - margin - last_pos, last_pos),
                        '+repage', img, img2
                    ])
                last_pos = value + margin

                if re.match(r'[0-9]+\.[0-9]+', str(destination)):
                    page, page_pos = [int(e) for e in destination.split('.')]
                else:
                    page = destination
                    page_pos = 0

                save(root_folder, img2, '{}-split'.format(context.get_process_count()))
                marging_horizontal = 10
                maring_vertical = 7
                context.image = cv2.imread(img2)
                crop(
                    context,
                    int(round(marging_horizontal / 10 / 2.51 * 300)),
                    int(round(maring_vertical / 10 / 2.51 * 300)),
                )
                img3_file = tempfile.NamedTemporaryFile(suffix='.png')
                img3 = img3_file.name
                cv2.imwrite(img3, context.image)
                save(root_folder, img3, '{}-crop'.format(context.get_process_count()))
                if page not in append:
                    append[page] = []
                append[page].append({
                    'file': img3_file,
                    'pos': page_pos,
                    'vertical': vertical
                })
        process_count = context.process_count

    for page_number in sorted(append.keys()):
        items = append[page_number]
        vertical = items[0]['vertical']
        for element in items:
            if element['vertical'] != vertical:
                raise Exception("Mix of limit type for page '{}'".format(page_number))

        process_file = tempfile.NamedTemporaryFile(suffix='.png')
        img = process_file.name
        call(CONVERT + [e['file'].name for e in sorted(items, key=lambda e: e['pos'])] + [
            '-background', '#ffffff', '-gravity', 'center', '+append' if vertical else '-append', img
        ])
        save(root_folder, img, '{}-split'.format(process_count))
        img2 = os.path.join(root_folder, 'image-{}.png'.format(page_number))
        call(CONVERT + [img, img2])
        transformed_images.append(img2)
    process_count += 1

    return {
        'sources': transformed_images,
        'name': 'finalise',
        'process_count': process_count,
    }


def finalise(config: Dict[str, Any], step: Dict[str, Any], root_folder: str) -> None:
    """
    Final step on document generation (convert in one pdf and copy with the right name in the cusume folder)
    """

    full_name = config['full_name']
    destination = config['destination']

    if os.path.exists(destination):
        return

    images = step['sources']

    if config['args']['append_credit_card']:
        images2 = []
        for img in images:
            if os.path.exists(img):
                images2.append(img)

        file_name = os.path.join(root_folder, 'append.png')
        call(CONVERT + images2 + [
            '-background', '#ffffff', '-gravity', 'center', '-append', file_name
        ])
        # To stack vertically (img1 over img2):
        # vis = np.concatenate((img1, img2), axis=0)
        # To stack horizontally (img1 to the left of img2):
        # vis = np.concatenate((img1, img2), axis=1)
        images = [file_name]

    pdf = []
    for img in images:
        if os.path.exists(img):
            name = os.path.splitext(os.path.basename(img))[0]
            file_name = os.path.join(root_folder, '{}.pdf'.format(name))
            if config['args'].get('tesseract', True):
                call(
                    'tesseract -l fra+eng {} stdout pdf > {}'.format(img, file_name),
                    shell=True  # nosec
                )
            else:
                call(CONVERT + [img, '+repage', file_name])
            pdf.append(file_name)

    call(['pdftk'] + pdf + ['output', destination, 'compress'])
    call(['exiftool', '-overwrite_original_in_place', '-Title=' + full_name, destination])


def write_error(root_folder: str, message: str) -> None:
    if not os.path.exists(os.path.join(root_folder, 'error.yaml')):
        with open(os.path.join(root_folder, 'error.yaml'), 'w') as error_file:
            error_file.write(yaml.safe_dump({
                'error': message,
            }, default_flow_style=False))


def is_sources_present(step: Dict[str, Any], root_folder: str) -> bool:
    for img in step['sources']:
        if not os.path.exists(os.path.join(root_folder, img)):
            return False
    return True


def save_config(config: Dict[str, Any], config_file_name: str) -> None:
    with open(config_file_name + '_', 'w') as config_file:
        config_file.write(yaml.safe_dump(config, default_flow_style=False))
    os.rename(config_file_name + '_', config_file_name)


def main() -> None:
    """
    Main function
    """
    print('Welcome to scanned images document to paperless.')
    while True:
        for config_file_name in glob.glob('/source/*/config.yaml'):
            if not os.path.exists(config_file_name):
                continue

            root_folder = os.path.dirname(config_file_name)

            if os.path.exists(os.path.join(root_folder, 'error.yaml')):
                continue

            with open(config_file_name) as config_file:
                config = yaml.safe_load(config_file.read())
            if config is None:
                write_error(root_folder, 'Empty config')
                continue

            try:
                if 'steps' not in config or config['steps']:
                    step = {
                        'sources': config['images'],
                        'name': 'transform',
                    }
                else:
                    config['steps'] = config['steps'][-1]

                if is_sources_present(step, root_folder):
                    if os.path.exists(os.path.join(root_folder, 'REMOVE_TO_CONTINUE')):
                        continue
                    if os.path.exists(os.path.join(root_folder, 'DONE')):
                        continue

                    done = False
                    next_step = None
                    if step['name'] == 'transform':
                        print(config_file_name)
                        print("Transform")
                        next_step = transform(config, step, config_file_name, root_folder)
                    elif step['name'] == 'split':
                        print(config_file_name)
                        print("Split")
                        next_step = split(config, step, root_folder)
                    elif step['name'] == 'finalise':
                        print(config_file_name)
                        print("Finalise")
                        finalise(config, step, root_folder)
                        done = True

                    if done and os.environ.get("PROGRESS", "FALSE") != "TRUE":
                        shutil.rmtree(root_folder)
                    else:
                        if next_step is not None:
                            config['steps'].append(next_step)
                        save_config(config, config_file_name)
                        with open(os.path.join(root_folder, 'DONE' if done else 'REMOVE_TO_CONTINUE'), 'w'):
                            pass
                else:
                    print(config_file_name)
                    if config['steps']:
                        print("Waiting image")
                    else:
                        config['steps'] = config['steps'][:-1]
                        save_config(config, config_file_name)
                        print("Rerun step")
                    continue
            except Exception as exception:
                print(exception)
                try:
                    with open(os.path.join(root_folder, 'error.yaml'), 'w') as error_file:
                        error_file.write(yaml.dump({
                            'error': exception,
                            'traceback': traceback.format_exc().split('\n'),
                        }, default_flow_style=False))
                except Exception as exception2:
                    print(exception2)
                    with open(os.path.join(root_folder, 'error.yaml'), 'w') as error_file:
                        error_file.write(yaml.safe_dump({
                            'error': str(exception2),
                            'traceback': traceback.format_exc().split('\n'),
                        }, default_flow_style=False))

        sys.stdout.flush()
        time.sleep(30)


if __name__ == "__main__":
    main()
